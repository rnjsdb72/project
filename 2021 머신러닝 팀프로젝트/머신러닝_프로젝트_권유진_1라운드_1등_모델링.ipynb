{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rc('font',family='malgun gothic')\n",
    "plt.rc('axes',unicode_minus=False)\n",
    "import seaborn as sns\n",
    "\n",
    "# EDA\n",
    "import klib\n",
    "\n",
    "# Preprocessing&Feature Engineering\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, PowerTransformer, RobustScaler, MaxAbsScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from bayes_opt import BayesianOptimization\n",
    "import kerastuner as kt\n",
    "\n",
    "# Modeling\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, ARDRegression, BayesianRidge, Lars\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor, StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import tensorflow as tf\n",
    "from vecstack import StackingTransformer\n",
    "from vecstack import stacking\n",
    "\n",
    "# Eveluation\n",
    "from sklearn.metrics import mean_squared_error # squared=False시 RMSE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Utility\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import platform\n",
    "from itertools import combinations\n",
    "from scipy.stats.mstats import gmean\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660af4af",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1dad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.abspath(\"../input\")+'/X_train.csv', encoding='cp949')\n",
    "y_train = pd.read_csv(os.path.abspath(\"../input\")+'/y_train.csv', encoding='cp949').set_index('custid')\n",
    "df_test = pd.read_csv(os.path.abspath(\"../input\")+'/X_test.csv', encoding='cp949')\n",
    "test_id = df_test['custid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath(\"../input\")+'/1st_train_features.pkl','rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with open(os.path.abspath(\"../input\")+'/1st_test_features.pkl','rb') as f:\n",
    "    x_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abc990",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(pd.DataFrame(x_test).fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6850344b",
   "metadata": {},
   "source": [
    "### Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8d8493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train2, x_dev, y_train2, y_dev = train_test_split(x_train, y_train, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10393c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'alpha':(0,50)\n",
    "}\n",
    "def rid_opt(alpha):\n",
    "    params = {\n",
    "        'alpha':alpha\n",
    "    }\n",
    "    rid = Ridge(random_state=0, **params)\n",
    "    rid.fit(x_train2,y_train2)\n",
    "    score = mean_squared_error(rid.predict(x_dev),y_dev,squared=False)\n",
    "    return -score\n",
    "BO_rid = BayesianOptimization(rid_opt, pbounds, random_state=0)\n",
    "BO_rid.maximize(init_points=50, n_iter=50) # init_points: exploration, n_iter: iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97bed16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'alpha':(0,50)\n",
    "}\n",
    "def las_opt(alpha):\n",
    "    params = {\n",
    "        'alpha':alpha\n",
    "    }\n",
    "    las = Lasso(random_state=0, **params)\n",
    "    las.fit(x_train2,y_train2)\n",
    "    score = mean_squared_error(las.predict(x_dev),y_dev,squared=False)\n",
    "    return -score\n",
    "BO_las = BayesianOptimization(las_opt, pbounds, random_state=0)\n",
    "BO_las.maximize(init_points=50, n_iter=50) # init_points: exploration, n_iter: iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403848e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'alpha':(0,50)\n",
    "}\n",
    "def ela_opt(alpha):\n",
    "    params = {\n",
    "        'alpha':alpha\n",
    "    }\n",
    "    ela = ElasticNet(random_state=0, **params)\n",
    "    ela.fit(x_train2,y_train2)\n",
    "    score = mean_squared_error(ela.predict(x_dev),y_dev,squared=False)\n",
    "    return -score\n",
    "BO_ela = BayesianOptimization(ela_opt, pbounds, random_state=0)\n",
    "BO_ela.maximize(init_points=50, n_iter=50) # init_points: exploration, n_iter: iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f501a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'n_iter':(100,1000),\n",
    "    'alpha_1':(0,50),\n",
    "    'alpha_2':(0,50),\n",
    "    'lambda_1':(0,10),\n",
    "    'lambda_2':(0,10)\n",
    "}\n",
    "def ard_opt(n_iter,alpha_1,alpha_2,lambda_1,lambda_2):\n",
    "    params = {\n",
    "        'n_iter':int(round(n_iter)),\n",
    "        'alpha_1':alpha_1,\n",
    "        'alpha_2':alpha_2,\n",
    "        'lambda_1':lambda_1,\n",
    "        'lambda_2':lambda_2\n",
    "    }\n",
    "    ard = ARDRegression(**params)\n",
    "    ard.fit(x_train2,y_train2)\n",
    "    score = mean_squared_error(ard.predict(x_dev),y_dev,squared=False)\n",
    "    return -score\n",
    "BO_ard = BayesianOptimization(ard_opt, pbounds, random_state=0)\n",
    "BO_ard.maximize(init_points=50, n_iter=50) # init_points: exploration, n_iter: iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71559a5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'n_iter':(100,1000),\n",
    "    'alpha_1':(0,50),\n",
    "    'alpha_2':(0,50),\n",
    "    'lambda_1':(0,10),\n",
    "    'lambda_2':(0,10)\n",
    "}\n",
    "def bay_opt(n_iter,alpha_1,alpha_2,lambda_1,lambda_2):\n",
    "    params = {\n",
    "        'n_iter':int(round(n_iter)),\n",
    "        'alpha_1':alpha_1,\n",
    "        'alpha_2':alpha_2,\n",
    "        'lambda_1':lambda_1,\n",
    "        'lambda_2':lambda_2\n",
    "    }\n",
    "    bay = BayesianRidge(**params)\n",
    "    bay.fit(x_train2,y_train2)\n",
    "    score = mean_squared_error(bay.predict(x_dev),y_dev,squared=False)\n",
    "    return -score\n",
    "BO_bay = BayesianOptimization(bay_opt, pbounds, random_state=0)\n",
    "BO_bay.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550f14f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbounds = {\n",
    "    'n_estimators':(100,1000),\n",
    "    'learning_rate':(0,1),\n",
    "    'max_depth':(2, 32),\n",
    "    'num_leaves':(2, 64),\n",
    "    'min_child_samples':(10, 200),\n",
    "    'min_child_weight':(1, 50),\n",
    "    'subsample':(0.5, 1),\n",
    "    'colsample_bytree':(0.5, 1),\n",
    "    'max_bin':(10, 500),\n",
    "    'reg_lambda':(0.001, 10),\n",
    "    'reg_alpha':(0.01, 50)\n",
    "}\n",
    "def lgbm_opt(n_estimators, learning_rate, max_depth, num_leaves, min_child_samples, min_child_weight,\n",
    "             subsample, colsample_bytree, max_bin, reg_lambda, reg_alpha):\n",
    "    params = {\n",
    "        \"n_estimators\":int(round(n_estimators)), \n",
    "        \"learning_rate\":learning_rate,\n",
    "        'max_depth':int(round(max_depth)),\n",
    "        'num_leaves':int(round(num_leaves)),\n",
    "        'min_child_samples': int(round(min_child_samples)),\n",
    "        'min_child_weight': int(round(min_child_weight)),\n",
    "        'subsample':max(min(subsample, 1), 0),\n",
    "        'colsample_bytree':max(min(colsample_bytree, 1), 0),\n",
    "        'reg_lambda': reg_lambda,\n",
    "        'reg_alpha': reg_alpha\n",
    "    }\n",
    "    lgbm = LGBMRegressor(random_state=0, **params)\n",
    "    lgbm.fit(x_train2,y_train2)\n",
    "    score = mean_squared_error(lgbm.predict(x_dev),y_dev,squared=False)\n",
    "    return -score\n",
    "BO_lgbm = BayesianOptimization(lgbm_opt, pbounds, random_state=0)\n",
    "BO_lgbm.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299d7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params_rid = BO_rid.max['params']\n",
    "max_params_las = BO_las.max['params']\n",
    "max_params_ela = BO_ela.max['params']\n",
    "max_params_ard = BO_ard.max['params']\n",
    "max_params_bay = BO_bay.max['params']\n",
    "max_params_lgbm = BO_lgbm.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f15f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params_ard['n_iter'] = int(round(max_params_ard['n_iter']))\n",
    "\n",
    "max_params_bay['n_iter'] = int(round(max_params_bay['n_iter']))\n",
    "\n",
    "max_params_lgbm['num_leaves'] = int(round(max_params_lgbm['num_leaves']))\n",
    "max_params_lgbm['n_estimators'] = int(round(max_params_lgbm['n_estimators']))\n",
    "max_params_lgbm['max_depth'] = int(round(max_params_lgbm['max_depth']))\n",
    "max_params_lgbm['min_child_samples'] = int(round(max_params_lgbm['min_child_samples']))\n",
    "max_params_lgbm['min_child_weight'] = int(round(max_params_lgbm['min_child_weight']))\n",
    "max_params_lgbm['max_bin'] = int(round(max_params_lgbm['max_bin']))\n",
    "max_params_lgbm['subsample'] = max(min(max_params_lgbm['subsample'], 1), 0)\n",
    "max_params_lgbm['colsample_bytree'] = max(min(max_params_lgbm['colsample_bytree'], 1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19df9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_params_rid,'\\n',max_params_las,'\\n',max_params_ela,'\\n',max_params_ard,'\\n',max_params_bay,'\\n',max_params_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs_tuned = [Ridge(random_state=0, **max_params_rid),Lasso(random_state=0, **max_params_las),ElasticNet(random_state=0, **max_params_ela),\n",
    "             ARDRegression(**max_params_ard),BayesianRidge(**max_params_bay),LGBMRegressor(random_state=0,**max_params_lgbm),CatBoostRegressor(random_state=0)]\n",
    "regs_tuned = [(str(reg).split('(')[0], reg) for reg in regs_tuned]\n",
    "regs_tuned[-1] = list(regs_tuned[-1])\n",
    "regs_tuned[-1][0] = 'CatBoostRegressor'\n",
    "regs_tuned[-1] = tuple(regs_tuned[-1])\n",
    "\n",
    "regs_trained = [(name, reg.fit(x_train2,y_train2), float(mean_squared_error(reg.predict(x_dev),y_dev,squared=False))) \n",
    "                    for name, reg in tqdm(regs_tuned.copy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e5642",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs_tuned = [Ridge(random_state=0, **max_params_rid),Lasso(random_state=0, **max_params_las),ElasticNet(random_state=0, **max_params_ela),\n",
    "             ARDRegression(**max_params_ard),BayesianRidge(**max_params_bay),LGBMRegressor(random_state=0,**max_params_lgbm),CatBoostRegressor(random_state=0)]\n",
    "regs_tuned = [(str(reg).split('(')[0], reg) for reg in regs_tuned]\n",
    "regs_tuned[-1] = list(regs_tuned[-1])\n",
    "regs_tuned[-1][0] = 'CatBoostRegressor'\n",
    "regs_tuned[-1] = tuple(regs_tuned[-1])\n",
    "\n",
    "regs_trained_for_submissions = [(name, reg.fit(x_train,y_train)) for name, reg in tqdm(regs_tuned.copy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406e644",
   "metadata": {},
   "outputs": [],
   "source": [
    "regs_tuned = [Ridge(random_state=0, **max_params_rid),Lasso(random_state=0, **max_params_las),ElasticNet(random_state=0, **max_params_ela),\n",
    "             ARDRegression(**max_params_ard),BayesianRidge(**max_params_bay),LGBMRegressor(random_state=0,**max_params_lgbm),CatBoostRegressor(random_state=0)]\n",
    "regs_tuned = [(str(reg).split('(')[0], reg) for reg in regs_tuned]\n",
    "regs_tuned[-1] = list(regs_tuned[-1])\n",
    "regs_tuned[-1][0] = 'CatBoostRegressor'\n",
    "regs_tuned[-1] = tuple(regs_tuned[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32b466",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = []\n",
    "for name, reg, reg_score in regs_trained:\n",
    "    pred = list(reg.predict(x_dev))\n",
    "    name = f'{name} \\n({reg_score:.4f})'\n",
    "    pred_results.append(pd.Series(pred, name=name))\n",
    "ensemble_results = pd.concat(pred_results, axis=1)\n",
    "ensemble_results = ensemble_results.applymap(lambda x: float(x))\n",
    "\n",
    "# 모형의 예측값 간의 상관관계를 보기 위해 hitmap을 도식한다.\n",
    "plt.figure(figsize = (8,6))\n",
    "g = sns.heatmap(ensemble_results.corr(), annot=True, cmap='Blues')\n",
    "g.set_title(\"Correlation between models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5695843",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = (ensemble_results.corr().sum()-1)/(ensemble_results.corr().shape[0]-1)\n",
    "names = corr.index\n",
    "rmse = np.array(corr.index.str[-7:-1]).astype(float)\n",
    "df = pd.DataFrame({'model': names, 'rmse': rmse, 'cor': corr})        \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "g = sns.scatterplot(x=\"cor\", y=\"rmse\", data=df, s=40, color='red')\n",
    "for line in range(0, df.shape[0]):\n",
    "     g.text(df.cor[line]+0.003, df.rmse[line]-0.003, \n",
    "            df.model[line], horizontalalignment='left', \n",
    "            size='medium', color='black', weight='semibold')\n",
    "        \n",
    "plt.xlim((df.cor.min()-0.01,df.cor.max()+0.01))\n",
    "plt.ylim((df.rmse.min()-0.01,df.rmse.max()+0.01))\n",
    "plt.xlabel('Mean Agreement')\n",
    "plt.ylabel('RMSE')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdd4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = [#'LinearRegression',\n",
    "            #'Ridge',\n",
    "            #'Lasso',\n",
    "            #'ElasticNet',\n",
    "            #'ARDRegression',\n",
    "            #'BayesianRidge',\n",
    "            #'RandomForestRegressor',\n",
    "            #'XGBRegressor',\n",
    "            'LGBMRegressor',\n",
    "            'CatBoostRegressor',\n",
    "            #'DeepNeuralNetwork'\n",
    "            ]\n",
    "models_for_ensemble = [(name,reg) for name,reg,score in regs_trained if name in selected]\n",
    "results_for_ensemble = []\n",
    "for name, model in models_for_ensemble:\n",
    "    results_for_ensemble.append(model.predict(x_dev))\n",
    "avg = (results_for_ensemble[0]+results_for_ensemble[1])/len(results_for_ensemble)\n",
    "score = mean_squared_error(avg, y_dev, squared=False)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c612b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected = [#'LinearRegression',\n",
    "            #'Ridge',\n",
    "            #'Lasso',\n",
    "            'ElasticNet',\n",
    "            #'ARDRegression',\n",
    "            #'BayesianRidge',\n",
    "            #'RandomForestRegressor',\n",
    "            #'XGBRegressor',\n",
    "            'LGBMRegressor',\n",
    "            'CatBoostRegressor',\n",
    "            #'DeepNeuralNetwork'\n",
    "            ]\n",
    "models_for_ensemble = [(name,reg) for name,reg,score in regs_trained if name in selected]\n",
    "results_for_ensemble = []\n",
    "weights_avg = []\n",
    "rmse_best = 1000\n",
    "for i in tqdm(range(1, 90, 1)):\n",
    "    for j in range(1, 90, 1):\n",
    "        for k in range(1, 90, 1):\n",
    "            if (i+j+k) != 90:\n",
    "                continue\n",
    "            pred = (models_for_ensemble[0][1].predict(x_dev).flatten() * i + models_for_ensemble[1][1].predict(x_dev) * j\n",
    "                    + models_for_ensemble[2][1].predict(x_dev) * k)/90\n",
    "            rmse = np.sqrt(mean_squared_error(y_dev, pred))\n",
    "            if rmse < rmse_best:\n",
    "                weights_avg = [i,j,k]\n",
    "                rmse_best = rmse \n",
    "                print(rmse, i,j,k)            \n",
    "\n",
    "print(rmse_best, weights_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0,w1,w2 = weights_avg\n",
    "selected = [#'LinearRegression',\n",
    "            #'Ridge',\n",
    "            #'Lasso',\n",
    "            'ElasticNet',\n",
    "            #'ARDRegression',\n",
    "            #'BayesianRidge',\n",
    "            #'RandomForestRegressor',\n",
    "            #'XGBRegressor',\n",
    "            'LGBMRegressor',\n",
    "            'CatBoostRegressor',\n",
    "            #'DeepNeuralNetwork'\n",
    "            ]\n",
    "models_for_ensemble = [(name,reg) for name,reg,score in regs_trained if name in selected]\n",
    "results_for_ensemble = []\n",
    "avg = (models_for_ensemble[0][1].predict(x_dev).flatten() * i + models_for_ensemble[1][1].predict(x_dev) * j\n",
    "                    + models_for_ensemble[2][1].predict(x_dev) * k)/90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6236b2",
   "metadata": {},
   "source": [
    "### Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ecb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seeds(reset_graph_with_backend=None):\n",
    "    if reset_graph_with_backend is not None:\n",
    "        K = reset_graph_with_backend\n",
    "        K.clear_session()\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        print(\"KERAS AND TENSORFLOW GRAPHS RESET\")  # optional\n",
    "\n",
    "    np.random.seed(99)\n",
    "    # seed를 잘 설정하면 성능이 더 잘 오른다.\n",
    "    random.seed(9)\n",
    "    tf.compat.v1.set_random_seed(16)\n",
    "#    os.environ['CUDA_VISIBLE_DEVICES'] = ''  # for GPU\n",
    "    print(\"RANDOM SEEDS RESET\")  # optional\n",
    "   \n",
    "reset_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(round(x_train2.shape[0] * 0.8,0))\n",
    "x_val, y_val = x_train2[i:], y_train2[i:]\n",
    "x_train3, y_train3 = x_train2[:i], y_train2[:i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(hp):\n",
    "    inputs = tf.keras.Input(shape=(x_train3.shape[1],))\n",
    "    x = inputs\n",
    "    for i in range(hp.Int('num_layers', 2, 4, step=1)):\n",
    "        x = tf.keras.layers.Dense(hp.Int('unit_'+str(i), 16, 128, step=16),\n",
    "                               activation=hp.Choice('activation',['relu','tanh']))(x)\n",
    "        x = tf.keras.layers.Dropout(hp.Float('dropout_'+str(i), 0, 0.5, step=0.25, default=0.5))(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    model.compile(loss='mse', \n",
    "                  optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), \n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras tuner는 튜닝 종류가 4종류가 있음: hyperband, grid search, random search, bayesian optimization\n",
    "tuner = kt.Hyperband(model_fn,\n",
    "                     objective=kt.Objective('val_root_mean_squared_error', direction=\"min\"), \n",
    "                     max_epochs=30,\n",
    "                     hyperband_iterations=2,\n",
    "                     overwrite=True,\n",
    "                     directory='dnn_tuning')\n",
    "# objective: 튜닝 기준, hyperband_iterations:이거 자체에서 2번 반복\n",
    "# overwrite: False시, 기존을 근거로 해 재학습 안시킴\n",
    "\n",
    "tuner.search(x_train3, y_train3, validation_data=(x_val, y_val),\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping()])\n",
    "# 빨리 끝내려고 파라미터 저렇게 설정한 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary(1) # 1= 제일 성능이 좋은 놈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss & RMSE\n",
    "dnn = tuner.get_best_models(1)[0] # best model 중 가장 좋은 모델\n",
    "dnn.evaluate(x_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5056db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pd.DataFrame({'avg':avg,'dnn':dnn.predict(x_dev).flatten()}).corr(),annot=True,cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00124b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_avg = []\n",
    "rmse_best = 1000\n",
    "for i in tqdm(range(1, 100, 1)):\n",
    "    for j in range(1, 100, 1):\n",
    "        if (i+j) != 100:\n",
    "            continue\n",
    "        pred = (avg *i+ dnn.predict(x_dev).flatten() * j)/100\n",
    "        rmse = np.sqrt(mean_squared_error(y_dev, pred))\n",
    "        if rmse < rmse_best:\n",
    "            weights_avg = [i,j]\n",
    "            rmse_best = rmse \n",
    "            print(rmse, i,j)            \n",
    "\n",
    "print(rmse_best, weights_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661eaeb5",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778ab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0,w1,w2 = [11, 40, 39]\n",
    "selected = [#'LinearRegression',\n",
    "            #'Ridge',\n",
    "            #'Lasso',\n",
    "            'ElasticNet',\n",
    "            #'ARDRegression',\n",
    "            #'BayesianRidge',\n",
    "            #'RandomForestRegressor',\n",
    "            #'XGBRegressor',\n",
    "            'LGBMRegressor',\n",
    "            'CatBoostRegressor',\n",
    "            #'DeepNeuralNetwork'\n",
    "            ]\n",
    "models_for_ensemble = [(name,reg) for name,reg,score in regs_trained if name in selected]\n",
    "results_for_ensemble = []\n",
    "avg = (models_for_ensemble[0][1].predict(x_dev).flatten() * w0 + models_for_ensemble[1][1].predict(x_dev) * w1\n",
    "                    + models_for_ensemble[2][1].predict(x_dev) * w2)/90\n",
    "pd.DataFrame({'age':avg}).to_csv('1등feature모델링_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f717deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0,w1,w2 = [11, 40, 39]\n",
    "selected = [#'LinearRegression',\n",
    "            #'Ridge',\n",
    "            #'Lasso',\n",
    "            'ElasticNet',\n",
    "            #'ARDRegression',\n",
    "            #'BayesianRidge',\n",
    "            #'RandomForestRegressor',\n",
    "            #'XGBRegressor',\n",
    "            'LGBMRegressor',\n",
    "            'CatBoostRegressor',\n",
    "            #'DeepNeuralNetwork'\n",
    "            ]\n",
    "models_for_ensemble = [(name,reg) for name,reg in regs_trained_for_submissions if name in selected]\n",
    "results_for_ensemble = []\n",
    "avg = (models_for_ensemble[0][1].predict(x_test).flatten() * w0 + models_for_ensemble[1][1].predict(x_test) * w1\n",
    "                    + models_for_ensemble[2][1].predict(x_test) * w2)/90\n",
    "pd.DataFrame({'custid': test_id, 'age':avg}).to_csv('1등feature모델링.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
